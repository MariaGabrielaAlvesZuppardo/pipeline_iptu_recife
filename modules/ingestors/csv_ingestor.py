import zipfile
import pandas as pd
import unicodedata
from io import BytesIO
from modules.utils.logger import setup_logger


class CSVIngestor:
    """
    Ingestor para arquivos CSV dentro de ZIPs.
    Apenas carrega os dados brutos, SEM validaÃ§Ã£o.
    """
    
    def __init__(self, zip_buffer: BytesIO, csv_filename: str):
        """
        Args:
            zip_buffer: Buffer em memÃ³ria contendo o arquivo ZIP
            csv_filename: Nome do arquivo CSV dentro do ZIP
        """
        self.zip_buffer = zip_buffer
        self.csv_filename = csv_filename
        # ðŸŸ¢ CORREÃ‡ÃƒO 1: Logger como atributo de instÃ¢ncia
        self.logger = setup_logger(self.__class__.__name__)
        
    def _fix_column_names(self, df: pd.DataFrame) -> pd.DataFrame:
        # ... (seu cÃ³digo de correÃ§Ã£o de nomes de coluna) ...
        # ...
        
        # O restante da funÃ§Ã£o _fix_column_names nÃ£o foi incluÃ­do,
        # mas presumimos que estÃ¡ correto e usa 'self' se precisar.
        
        replacements = {
            'Ãƒ': 'Ã£', 'ÃƒÂ§': 'Ã§', 'ÃƒÂ©': 'Ã©', 'ÃƒÂ³': 'Ã³', 'ÃƒÂ­': 'Ã­', 
            'ÃƒÂº': 'Ãº', 'ÃƒÂ¡': 'Ã¡', 'ÃƒÂ£': 'Ã£', 'ÃƒÂª': 'Ãª', 
        }
        
        new_columns = {}
        for col in df.columns:
            new_col = col
            for bad, good in replacements.items():
                new_col = new_col.replace(bad, good)
            
            new_col = ''.join(char for char in new_col if unicodedata.category(char)[0] != 'C')
            
            new_columns[col] = new_col
        
        return df.rename(columns=new_columns)

    
    def load(self) -> pd.DataFrame:
        """
        Carrega o CSV do ZIP em CHUNKS para evitar estouro de memÃ³ria...
        """
        CHUNK_SIZE = 50000 
        
        # ðŸ’¡ NÃƒO PRECISA MAIS DE all_chunks aqui, ele serÃ¡ definido dentro do try
        
        try:
            # ðŸŸ¢ CORREÃ‡ÃƒO 1: Uso de self.logger
            self.logger.info(f"Lendo arquivo {self.csv_filename} do ZIP em chunks (tamanho: {CHUNK_SIZE})...")
            
            with zipfile.ZipFile(self.zip_buffer, 'r') as z:
                
                file_list = z.namelist()
                # ðŸŸ¢ CORREÃ‡ÃƒO 1: Uso de self.logger
                self.logger.debug(f"Arquivos encontrados no ZIP: {file_list}")
                
                # --- LÃ³gica de busca de arquivo (adaptada para um exemplo mais completo) ---
                csv_file = None
                for f in file_list:
                    if f.lower().endswith('.csv') and self.csv_filename.lower() in f.lower():
                        csv_file = f
                        break
                
                if not csv_file:
                    raise FileNotFoundError(
                        f"Arquivo CSV '{self.csv_filename}' nÃ£o encontrado no ZIP. "
                        f"Arquivos disponÃ­veis: {file_list}"
                    )
                
                # ðŸŸ¢ CORREÃ‡ÃƒO 1: Uso de self.logger
                self.logger.info(f"Arquivo encontrado: {csv_file}")
                
                
                # ðŸŸ¢ CORREÃ‡ÃƒO 2: A funÃ§Ã£o interna agora aceita a lista de chunks como argumento
                def read_in_chunks(file_handle, encoding, chunk_list):
                    chunk_iterator = pd.read_csv(
                        file_handle,
                        encoding=encoding,
                        sep=';',
                        chunksize=CHUNK_SIZE, 
                        na_values=['', 'NULL', 'null', 'NA', 'N/A'],
                        skipinitialspace=True
                    )
                    
                    for i, chunk in enumerate(chunk_iterator):
                        # ðŸŸ¢ CORREÃ‡ÃƒO 1: Uso de self.logger
                        self.logger.debug(f"Lido chunk #{i+1} com {len(chunk)} registros")
                        chunk_list.append(chunk)
                    
                    return pd.concat(chunk_list, ignore_index=True)

                
                with z.open(csv_file) as f:
                    # 1. Tentar UTF-8 com BOM
                    all_chunks_utf8 = [] # ðŸŸ¢ CORREÃ‡ÃƒO 2: Nova lista de chunks
                    try:
                        self.logger.debug("Tentando encoding 'utf-8-sig'")
                        df = read_in_chunks(f, 'utf-8-sig', all_chunks_utf8)
                    except UnicodeDecodeError:
                        # 2. Fallback para latin1
                        # ðŸŸ¢ CORREÃ‡ÃƒO 1: Uso de self.logger
                        self.logger.warning("UTF-8 falhou, tentando latin1...")
                        
                        # Reabrir o arquivo para garantir que a leitura comece do zero
                        with z.open(csv_file) as f2:
                             all_chunks_latin1 = [] # ðŸŸ¢ CORREÃ‡ÃƒO 2: Nova lista de chunks
                             df = read_in_chunks(f2, 'latin1', all_chunks_latin1)

                
                # ðŸŸ¢ CORREÃ‡ÃƒO 1: Uso de self.logger
                self.logger.info(f"âœ“ CSV carregado: {len(df)} registros, {len(df.columns)} colunas")
                
                # Corrigir nomes de colunas com problemas de encoding
                df = self._fix_column_names(df)
                
                # ðŸŸ¢ CORREÃ‡ÃƒO 1: Uso de self.logger
                self.logger.debug(f"Colunas: {list(df.columns)}")
                
                return df
                
        except FileNotFoundError as e:
            # ðŸŸ¢ CORREÃ‡ÃƒO 1: Uso de self.logger
            self.logger.error(f"Erro: {e}")
            raise
        except Exception as e:
            # ðŸŸ¢ CORREÃ‡ÃƒO 1: Uso de self.logger
            self.logger.error(f"Erro ao ler CSV do ZIP: {e}")
            raise